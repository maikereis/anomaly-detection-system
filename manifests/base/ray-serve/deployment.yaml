apiVersion: apps/v1
kind: Deployment
metadata:
  name: ray-serve
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ray-serve
  template:
    metadata:
      labels:
        app: ray-serve
    spec:
      containers:
        - name: ray-serve
          image: anyscale/ray:2.52.0-slim-py312

          command:
            - /bin/bash
            - -c
            - |
              set -ex

              # Aguarda MLflow estar disponível
              until curl -sf http://mlflow-server:5000/health > /dev/null; do
                echo "Waiting for MLflow..."
                sleep 5
              done

              # Instala dependências Python
              pip install --quiet mlflow==3.6.0 boto3==1.42.4

              # Inicia Ray head node
              ray start --head --port=6379 --dashboard-host=0.0.0.0 --dashboard-port=8265

              # Deploy da aplicação Ray Serve
              cd /app && serve run serve_app:app

          ports:
            - containerPort: 8000
              name: serve
            - containerPort: 8265
              name: dashboard

          envFrom:
            - configMapRef:
                name: ray-serve-config
            - secretRef:
                name: ray-serve-secret

          volumeMounts:
            - name: serve-app
              mountPath: /app

          resources:
            requests:
              cpu: 1000m
              memory: 512Mi
            limits:
              cpu: 2000m
              memory: 2Gi

          readinessProbe:
            httpGet:
              path: /
              port: 8000
            initialDelaySeconds: 60
            periodSeconds: 10
            timeoutSeconds: 3
            failureThreshold: 3

      volumes:
        - name: serve-app
          configMap:
            name: ray-serve-app