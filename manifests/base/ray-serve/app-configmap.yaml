apiVersion: v1
kind: ConfigMap
metadata:
  name: ray-serve-app
data:
  serve_app.py: |
    """
    Ray Serve - Anomaly Detection API
    Carrega modelos do MLflow com fallback Z-score
    """
    import os
    import logging
    from typing import Optional
    from datetime import datetime
    
    import mlflow
    import numpy as np
    from ray import serve
    from starlette.requests import Request
    from starlette.responses import JSONResponse
    
    logging.basicConfig(level=os.getenv("RAY_LOGGING_LEVEL", "INFO"))
    logger = logging.getLogger(__name__)
    
    
    class ZScoreFallback:
        """Detector Z-score simples para quando modelo não existe"""
        
        def __init__(self, threshold: float = 3.0):
            self.threshold = threshold
            # Estatísticas hardcoded (em prod, buscar de cache/DB)
            self.stats = {
                "mean": 0.0,
                "std": 1.0
            }
        
        def predict(self, value: float) -> bool:
            """Retorna True se anomalia"""
            if self.stats["std"] == 0:
                return False
            z_score = abs((value - self.stats["mean"]) / self.stats["std"])
            return z_score > self.threshold
    
    
    @serve.deployment(
        num_replicas=2,
        autoscaling_config={
            "min_replicas": 2,
            "max_replicas": 10,
            "target_ongoing_requests": 5,
        }
    )
    class AnomalyDetector:
        def __init__(self):
            mlflow.set_tracking_uri(os.getenv("MLFLOW_TRACKING_URI"))
            self.client = mlflow.MlflowClient()
            self.fallback = ZScoreFallback(threshold=3.0)
            logger.info("AnomalyDetector initialized")
        
        def load_model(self, series_id: str, version: str = "Production"):
            """
            Carrega modelo do MLflow.
            Ray faz cache automaticamente.
            Retorna (model, source) onde source = 'mlflow' ou 'fallback'
            """
            try:
                model_name = f"model_od_{series_id}"
                model_uri = f"models:/{model_name}/{version}"
                model = mlflow.pyfunc.load_model(model_uri)
                logger.info(f"Loaded model {model_name}:{version} from MLflow")
                return model, "mlflow"
            
            except Exception as e:
                logger.warning(f"Model {series_id} not found, using fallback: {e}")
                return self.fallback, "fallback"
        
        async def __call__(self, request: Request) -> JSONResponse:
            try:
                # Parse request
                path = request.url.path
                series_id = path.split("/")[-1]
                body = await request.json()
                
                timestamp = body.get("timestamp")
                value = body.get("value")
                
                if not all([series_id, timestamp is not None, value is not None]):
                    return JSONResponse(
                        status_code=400,
                        content={"error": "Missing required fields: timestamp, value"}
                    )
                
                # Versão do modelo
                version = request.query_params.get("version", "Production")
                
                # Carrega modelo (ou fallback)
                model, source = self.load_model(series_id, version)
                
                # Predição
                if source == "fallback":
                    anomaly = model.predict(value)
                    model_version = "fallback"
                else:
                    prediction = model.predict([[value]])
                    anomaly = bool(prediction[0])
                    model_version = version
                
                return JSONResponse({
                    "anomaly": anomaly,
                    "model_version": model_version,
                    "timestamp": timestamp,
                    "value": value,
                    "model_source": source,
                    "processed_at": datetime.utcnow().isoformat()
                })
            
            except Exception as e:
                logger.error(f"Prediction error: {e}", exc_info=True)
                return JSONResponse(
                    status_code=500,
                    content={"error": str(e)}
                )
    
    
    # Entrypoint
    app = AnomalyDetector.bind()